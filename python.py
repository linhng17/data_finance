import streamlit as st
import pandas as pd
from google import genai
from google.genai.errors import APIError

# --- C·∫•u h√¨nh Trang Streamlit ---
st.set_page_config(
    page_title="App Ph√¢n T√≠ch B√°o C√°o T√†i Ch√≠nh",
    layout="wide"
)

st.title("·ª®ng d·ª•ng Ph√¢n T√≠ch B√°o C√°o T√†i Ch√≠nh üìä")

# --- Kh·ªüi t·∫°o State cho Chatbot v√† API Key ---
# S·ª≠ d·ª•ng state ƒë·ªÉ l∆∞u tr·ªØ l·ªãch s·ª≠ chat
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "chat_session" not in st.session_state:
    st.session_state.chat_session = None

# L·∫•y API Key t·ª´ Streamlit Secrets
API_KEY = st.secrets.get("GEMINI_API_KEY")

# Kh·ªüi t·∫°o client Gemini (ch·ªâ m·ªôt l·∫ßn)
if "client" not in st.session_state:
    if API_KEY:
        try:
            st.session_state.client = genai.Client(api_key=API_KEY)
        except Exception as e:
            st.error(f"L·ªói kh·ªüi t·∫°o Gemini Client: {e}")
            st.session_state.client = None
    else:
        # N·∫øu API Key kh√¥ng t·ªìn t·∫°i, client s·∫Ω l√† None
        st.session_state.client = None

# --- H√†m t√≠nh to√°n ch√≠nh (S·ª≠ d·ª•ng Caching ƒë·ªÉ T·ªëi ∆∞u hi·ªáu su·∫•t) ---
@st.cache_data
def process_financial_data(df):
    """Th·ª±c hi·ªán c√°c ph√©p t√≠nh TƒÉng tr∆∞·ªüng v√† T·ª∑ tr·ªçng."""
    
    # ƒê·∫£m b·∫£o c√°c gi√° tr·ªã l√† s·ªë ƒë·ªÉ t√≠nh to√°n
    numeric_cols = ['NƒÉm tr∆∞·ªõc', 'NƒÉm sau']
    for col in numeric_cols:
        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
    
    # 1. T√≠nh T·ªëc ƒë·ªô TƒÉng tr∆∞·ªüng
    # D√πng .replace(0, 1e-9) cho Series Pandas ƒë·ªÉ tr√°nh l·ªói chia cho 0
    df['T·ªëc ƒë·ªô tƒÉng tr∆∞·ªüng (%)'] = (
        (df['NƒÉm sau'] - df['NƒÉm tr∆∞·ªõc']) / df['NƒÉm tr∆∞·ªõc'].replace(0, 1e-9)
    ) * 100

    # 2. T√≠nh T·ª∑ tr·ªçng theo T·ªïng T√†i s·∫£n
    # L·ªçc ch·ªâ ti√™u "T·ªîNG C·ªòNG T√ÄI S·∫¢N"
    tong_tai_san_row = df[df['Ch·ªâ ti√™u'].str.contains('T·ªîNG C·ªòNG T√ÄI S·∫¢N', case=False, na=False)]
    
    if tong_tai_san_row.empty:
        raise ValueError("Kh√¥ng t√¨m th·∫•y ch·ªâ ti√™u 'T·ªîNG C·ªòNG T√ÄI S·∫¢N'.")

    tong_tai_san_N_1 = tong_tai_san_row['NƒÉm tr∆∞·ªõc'].iloc[0]
    tong_tai_san_N = tong_tai_san_row['NƒÉm sau'].iloc[0]

    # X·ª≠ l√Ω gi√° tr·ªã 0 th·ªß c√¥ng cho m·∫´u s·ªë ƒë·ªÉ t√≠nh t·ª∑ tr·ªçng
    divisor_N_1 = tong_tai_san_N_1 if tong_tai_san_N_1 != 0 else 1e-9
    divisor_N = tong_tai_san_N if tong_tai_san_N != 0 else 1e-9

    # T√≠nh t·ª∑ tr·ªçng v·ªõi m·∫´u s·ªë ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω
    df['T·ª∑ tr·ªçng NƒÉm tr∆∞·ªõc (%)'] = (df['NƒÉm tr∆∞·ªõc'] / divisor_N_1) * 100
    df['T·ª∑ tr·ªçng NƒÉm sau (%)'] = (df['NƒÉm sau'] / divisor_N) * 100
    
    return df

# --- H√†m g·ªçi API Gemini (H√†m c≈©) ---
def get_ai_analysis(data_for_ai, client):
    """G·ª≠i d·ªØ li·ªáu ph√¢n t√≠ch ƒë·∫øn Gemini API v√† nh·∫≠n nh·∫≠n x√©t."""
    if not client:
        return "L·ªói g·ªçi Gemini API: Client ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o do thi·∫øu Kh√≥a API."
        
    try:
        model_name = 'gemini-2.5-flash' 

        prompt = f"""
        B·∫°n l√† m·ªôt chuy√™n gia ph√¢n t√≠ch t√†i ch√≠nh chuy√™n nghi·ªáp. D·ª±a tr√™n c√°c ch·ªâ s·ªë t√†i ch√≠nh sau, h√£y ƒë∆∞a ra m·ªôt nh·∫≠n x√©t kh√°ch quan, ng·∫Øn g·ªçn (kho·∫£ng 3-4 ƒëo·∫°n) v·ªÅ t√¨nh h√¨nh t√†i ch√≠nh c·ªßa doanh nghi·ªáp. ƒê√°nh gi√° t·∫≠p trung v√†o t·ªëc ƒë·ªô tƒÉng tr∆∞·ªüng, thay ƒë·ªïi c∆° c·∫•u t√†i s·∫£n v√† kh·∫£ nƒÉng thanh to√°n hi·ªán h√†nh.
        
        D·ªØ li·ªáu th√¥ v√† ch·ªâ s·ªë:
        {data_for_ai}
        """

        response = client.models.generate_content(
            model=model_name,
            contents=prompt
        )
        return response.text

    except APIError as e:
        return f"L·ªói g·ªçi Gemini API: Vui l√≤ng ki·ªÉm tra Kh√≥a API ho·∫∑c gi·ªõi h·∫°n s·ª≠ d·ª•ng. Chi ti·∫øt l·ªói: {e}"
    except Exception as e:
        return f"ƒê√£ x·∫£y ra l·ªói kh√¥ng x√°c ƒë·ªãnh: {e}"
        
# --- H√†m kh·ªüi t·∫°o Chat Session ---
def initialize_chat_session(df_processed_markdown):
    """Kh·ªüi t·∫°o Chat Session v·ªõi System Instruction."""
    client = st.session_state.get("client")
    
    # B·ªî SUNG KI·ªÇM TRA: N·∫øu client kh√¥ng t·ªìn t·∫°i, b√°o l·ªói ngay l·∫≠p t·ª©c
    if not client:
        st.error("L·ªói kh·ªüi t·∫°o Chatbot: Kh√¥ng t√¨m th·∫•y Gemini Client (thi·∫øu Kh√≥a API).", icon="üö®")
        return False
    
    # System instruction ƒë·ªÉ Gemini hi·ªÉu ng·ªØ c·∫£nh
    system_instruction = f"""
    B·∫°n l√† m·ªôt Tr·ª£ l√Ω ph√¢n t√≠ch t√†i ch√≠nh chuy√™n nghi·ªáp v√† th√¢n thi·ªán, c√≥ kh·∫£ nƒÉng tr·∫£ l·ªùi c√°c c√¢u h·ªèi d·ª±a tr√™n d·ªØ li·ªáu B√°o c√°o T√†i ch√≠nh ƒë∆∞·ª£c cung c·∫•p.
    
    D·ªØ li·ªáu ph√¢n t√≠ch t√†i ch√≠nh hi·ªán t·∫°i c·ªßa c√¥ng ty:
    {df_processed_markdown}
    
    H√£y s·ª≠ d·ª•ng d·ªØ li·ªáu n√†y ƒë·ªÉ tr·∫£ l·ªùi c√°c c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng. N·∫øu th√¥ng tin kh√¥ng c√≥ trong b·∫£ng, h√£y tr·∫£ l·ªùi theo ki·∫øn th·ª©c t√†i ch√≠nh chung. Lu√¥n tr·∫£ l·ªùi b·∫±ng Ti·∫øng Vi·ªát.
    """
    
    try:
        # S·ª≠ d·ª•ng genai.types.GenerateContentConfig ƒë·ªÉ truy·ªÅn system_instruction (ƒë√£ s·ª≠a l·ªói TypeError tr∆∞·ªõc ƒë√≥)
        st.session_state.chat_session = client.chats.create(
            model="gemini-2.5-flash",
            config=genai.types.GenerateContentConfig(
                system_instruction=system_instruction
            )
        )
        st.session_state.chat_history.append({"role": "model", "content": "Ch√†o b·∫°n! T√¥i l√† Tr·ª£ l√Ω AI. H√£y h·ªèi t√¥i v·ªÅ d·ªØ li·ªáu t√†i ch√≠nh b·∫°n v·ª´a t·∫£i l√™n nh√©."})
        return True
    except APIError as e:
        st.error(f"L·ªói kh·ªüi t·∫°o Chat Session: L·ªói API ({e}). Vui l√≤ng ki·ªÉm tra Kh√≥a API.", icon="üö®")
        return False
    except Exception as e:
        st.error(f"L·ªói kh·ªüi t·∫°o Chat Session: ƒê√£ x·∫£y ra l·ªói kh√¥ng x√°c ƒë·ªãnh ({e}).", icon="üö®")
        return False


# --- H√†m x·ª≠ l√Ω Chatbot cho Pop-up ---
def handle_chatbot_input_popup(user_prompt, chat_container):
    """X·ª≠ l√Ω ƒë·∫ßu v√†o t·ª´ ng∆∞·ªùi d√πng v√† g·ª≠i ƒë·∫øn chat session c·ªßa Gemini."""
    
    if st.session_state.chat_session is None:
        chat_container.error("Chatbot ch∆∞a s·∫µn s√†ng. Vui l√≤ng nh·∫•n n√∫t **B·∫≠t/Reset Chat**.", icon="üö®")
        return

    # Th√™m c√¢u h·ªèi ng∆∞·ªùi d√πng v√†o l·ªãch s·ª≠
    st.session_state.chat_history.append({"role": "user", "content": user_prompt})

    # G·ª≠i tin nh·∫Øn ƒë·∫øn Gemini v√† hi·ªÉn th·ªã k·∫øt qu·∫£
    try:
        # Hi·ªÉn th·ªã tin nh·∫Øn ng∆∞·ªùi d√πng
        # S·ª≠ d·ª•ng chat_container ƒë·ªÉ hi·ªÉn th·ªã tin nh·∫Øn trong h·ªôp l·ªãch s·ª≠
        with chat_container.chat_message("user"):
            st.markdown(user_prompt)

        # Hi·ªÉn th·ªã ph·∫£n h·ªìi c·ªßa model
        with chat_container.chat_message("model"):
            with st.spinner("ƒêang ph√¢n t√≠ch..."):
                # S·ª¨A L·ªñI: ƒêo·∫°n code n√†y b·ªã l·ªói timeout ho·∫∑c l·ªói API call
                response = st.session_state.chat_session.send_message(user_prompt)
                model_response = response.text
            
            st.markdown(model_response)
        
        # Th√™m c√¢u tr·∫£ l·ªùi c·ªßa model v√†o l·ªãch s·ª≠
        st.session_state.chat_history.append({"role": "model", "content": model_response})
        
    except APIError as e:
        # S·ª¨A L·ªñI: C·∫≠p nh·∫≠t th√¥ng b√°o l·ªói chi ti·∫øt h∆°n
        error_message = f"L·ªói API: Kh√¥ng th·ªÉ nh·∫≠n ph·∫£n h·ªìi. Vui l√≤ng ki·ªÉm tra Kh√≥a API ho·∫∑c gi·ªõi h·∫°n s·ª≠ d·ª•ng. Chi ti·∫øt: {e}"
        st.error(error_message, icon="üö®")
        st.session_state.chat_history.append({"role": "model", "content": "L·ªói: Kh√¥ng th·ªÉ nh·∫≠n ph·∫£n h·ªìi t·ª´ AI do l·ªói API."})
    except Exception as e:
        error_message = f"L·ªói kh√¥ng x√°c ƒë·ªãnh: {e}"
        st.error(error_message, icon="üö®")
        st.session_state.chat_history.append({"role": "model", "content": "L·ªói: ƒê√£ x·∫£y ra l·ªói b·∫•t ng·ªù."})


# Kh·ªüi t·∫°o bi·∫øn ƒë·ªÉ gi·ªØ d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω
df_processed = None
df_processed_markdown = "" # Chu·ªói markdown c·ªßa d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω

# --- Ch·ª©c nƒÉng 1: T·∫£i File ---
uploaded_file = st.file_uploader(
    "1. T·∫£i file Excel B√°o c√°o T√†i ch√≠nh (Ch·ªâ ti√™u | NƒÉm tr∆∞·ªõc | NƒÉm sau)",
    type=['xlsx', 'xls']
)

if uploaded_file is not None:
    try:
        df_raw = pd.read_excel(uploaded_file)
        
        # Ti·ªÅn x·ª≠ l√Ω: ƒê·∫£m b·∫£o ch·ªâ c√≥ 3 c·ªôt quan tr·ªçng
        df_raw.columns = ['Ch·ªâ ti√™u', 'NƒÉm tr∆∞·ªõc', 'NƒÉm sau']
        
        # X·ª≠ l√Ω d·ªØ li·ªáu
        df_processed = process_financial_data(df_raw.copy())

        if df_processed is not None:
            df_processed_markdown = df_processed.to_markdown(index=False) # T·∫°o markdown cho Chatbot context
            
            # --- Ch·ª©c nƒÉng 2 & 3: Hi·ªÉn th·ªã K·∫øt qu·∫£ ---
            st.subheader("2. T·ªëc ƒë·ªô TƒÉng tr∆∞·ªüng & 3. T·ª∑ tr·ªçng C∆° c·∫•u T√†i s·∫£n")
            st.dataframe(df_processed.style.format({
                'NƒÉm tr∆∞·ªõc': '{:,.0f}',
                'NƒÉm sau': '{:,.0f}',
                'T·ªëc ƒë·ªô tƒÉng tr∆∞·ªüng (%)': '{:.2f}%',
                'T·ª∑ tr·ªçng NƒÉm tr∆∞·ªõc (%)': '{:.2f}%',
                'T·ª∑ tr·ªçng NƒÉm sau (%)': '{:.2f}%'
            }), use_container_width=True)
            
            # --- Ch·ª©c nƒÉng 4: T√≠nh Ch·ªâ s·ªë T√†i ch√≠nh ---
            st.subheader("4. C√°c Ch·ªâ s·ªë T√†i ch√≠nh C∆° b·∫£n")
            
            # Kh·ªüi t·∫°o gi√° tr·ªã m·∫∑c ƒë·ªãnh cho Ch·ª©c nƒÉng 5
            thanh_toan_hien_hanh_N = "N/A"
            thanh_toan_hien_hanh_N_1 = "N/A"
            
            try:
                # L·∫•y T√†i s·∫£n ng·∫Øn h·∫°n
                tsnh_n = df_processed[df_processed['Ch·ªâ ti√™u'].str.contains('T√ÄI S·∫¢N NG·∫ÆN H·∫†N', case=False, na=False)]['NƒÉm sau'].iloc[0]
                tsnh_n_1 = df_processed[df_processed['Ch·ªâ ti√™u'].str.contains('T√ÄI S·∫¢N NG·∫ÆN H·∫†N', case=False, na=False)]['NƒÉm tr∆∞·ªõc'].iloc[0]

                # L·∫•y N·ª£ ng·∫Øn h·∫°n
                no_ngan_han_N = df_processed[df_processed['Ch·ªâ ti√™u'].str.contains('N·ª¢ NG·∫ÆN H·∫†N', case=False, na=False)]['NƒÉm sau'].iloc[0]  
                no_ngan_han_N_1 = df_processed[df_processed['Ch·ªâ ti√™u'].str.contains('N·ª¢ NG·∫ÆN H·∫†N', case=False, na=False)]['NƒÉm tr∆∞·ªõc'].iloc[0]

                # Tr√°nh chia cho 0
                divisor_no_n = no_ngan_han_N if no_ngan_han_N != 0 else 1e-9
                divisor_no_n_1 = no_ngan_han_N_1 if no_ngan_han_N_1 != 0 else 1e-9
                
                # T√≠nh to√°n
                thanh_toan_hien_hanh_N = tsnh_n / divisor_no_n
                thanh_toan_hien_hanh_N_1 = tsnh_n_1 / divisor_no_n_1
                
                col1, col2 = st.columns(2)
                with col1:
                    st.metric(
                        label="Ch·ªâ s·ªë Thanh to√°n Hi·ªán h√†nh (NƒÉm tr∆∞·ªõc)",
                        value=f"{thanh_toan_hien_hanh_N_1:.2f} l·∫ßn"
                    )
                with col2:
                    st.metric(
                        label="Ch·ªâ s·ªë Thanh to√°n Hi·ªán h√†nh (NƒÉm sau)",
                        value=f"{thanh_toan_hien_hanh_N:.2f} l·∫ßn",
                        delta=f"{thanh_toan_hien_hanh_N - thanh_toan_hien_hanh_N_1:.2f}"
                    )
                    
            except IndexError:
                st.warning("Thi·∫øu ch·ªâ ti√™u 'T√ÄI S·∫¢N NG·∫ÆN H·∫†N' ho·∫∑c 'N·ª¢ NG·∫ÆN H·∫†N' ƒë·ªÉ t√≠nh ch·ªâ s·ªë.")
                thanh_toan_hien_hanh_N = "N/A"
                thanh_toan_hien_hanh_N_1 = "N/A"
            except ZeroDivisionError:
                st.warning("Kh√¥ng th·ªÉ t√≠nh Ch·ªâ s·ªë Thanh to√°n Hi·ªán h√†nh do N·ª£ Ng·∫Øn H·∫°n b·∫±ng 0.")
                thanh_toan_hien_hanh_N = "N/A"
                thanh_toan_hien_hanh_N_1 = "N/A"
                
            # --- Ch·ª©c nƒÉng 5: Nh·∫≠n x√©t AI T·ª± ƒë·ªông ---
            st.subheader("5. Nh·∫≠n x√©t T√¨nh h√¨nh T√†i ch√≠nh (AI)")
            
            # Chu·∫©n b·ªã d·ªØ li·ªáu ƒë·ªÉ g·ª≠i cho AI
            tsnh_tg_row = df_processed[df_processed['Ch·ªâ ti√™u'].str.contains('T√ÄI S·∫¢N NG·∫ÆN H·∫†N', case=False, na=False)]
            tsnh_tg = f"{tsnh_tg_row['T·ªëc ƒë·ªô tƒÉng tr∆∞·ªüng (%)'].iloc[0]:.2f}%" if not tsnh_tg_row.empty else "N/A"
            
            data_for_ai = pd.DataFrame({
                'Ch·ªâ ti√™u': [
                    'To√†n b·ªô B·∫£ng ph√¢n t√≠ch (d·ªØ li·ªáu th√¥)', 
                    'TƒÉng tr∆∞·ªüng T√†i s·∫£n ng·∫Øn h·∫°n (%)', 
                    'Thanh to√°n hi·ªán h√†nh (N-1)', 
                    'Thanh to√°n hi·ªán h√†nh (N)'
                ],
                'Gi√° tr·ªã': [
                    df_processed_markdown,
                    tsnh_tg, 
                    f"{thanh_toan_hien_hanh_N_1}", 
                    f"{thanh_toan_hien_hanh_N}"
                ]
            }).to_markdown(index=False) 

            if st.button("Y√™u c·∫ßu AI Ph√¢n t√≠ch"):
                client = st.session_state.get("client")
                
                if client:
                    with st.spinner('ƒêang g·ª≠i d·ªØ li·ªáu v√† ch·ªù Gemini ph√¢n t√≠ch...'):
                        ai_result = get_ai_analysis(data_for_ai, client)
                    st.markdown("**K·∫øt qu·∫£ Ph√¢n t√≠ch t·ª´ Gemini AI:**")
                    st.info(ai_result)
                else:
                    st.error("L·ªói: Kh√¥ng th·ªÉ th·ª±c hi·ªán Ph√¢n t√≠ch AI do thi·∫øu Kh√≥a API.")

    except ValueError as ve:
        st.error(f"L·ªói c·∫•u tr√∫c d·ªØ li·ªáu: {ve}")
    except Exception as e:
        st.error(f"C√≥ l·ªói x·∫£y ra khi ƒë·ªçc ho·∫∑c x·ª≠ l√Ω file: {e}. Vui l√≤ng ki·ªÉm tra ƒë·ªãnh d·∫°ng file v√† c√°c c·ªôt.")

else:
    st.info("Vui l√≤ng t·∫£i l√™n file Excel ƒë·ªÉ b·∫Øt ƒë·∫ßu ph√¢n t√≠ch.")
    

# ******************************************************************************
# --- PH·∫¶N B·ªî SUNG KHUNG CHAT RI√äNG BI·ªÜT (Pop-up m√¥ ph·ªèng) ---
# ******************************************************************************
st.markdown("---")
st.subheader("6. Tr·ª£ l√Ω Chatbot AI")
st.markdown("*(D√πng ƒë·ªÉ h·ªèi ƒë√°p chuy√™n s√¢u v·ªÅ d·ªØ li·ªáu t√†i ch√≠nh b·∫°n ƒë√£ t·∫£i l√™n)*")

# N√∫t B·∫≠t/Reset Chat
if df_processed is not None:
    # Ki·ªÉm tra l·∫°i client tr∆∞·ªõc khi c·ªë g·∫Øng kh·ªüi t·∫°o chat
    if st.button("B·∫≠t/Reset Chat", key="reset_chat", type="primary"):
        st.session_state.chat_session = None # X√≥a session c≈©
        st.session_state.chat_history = [] # X√≥a l·ªãch s·ª≠
        
        # Kh·ªüi t·∫°o session m·ªõi sau khi reset
        client = st.session_state.get("client")
        if client and df_processed_markdown:
            if initialize_chat_session(df_processed_markdown):
                # Kh·ªüi t·∫°o th√†nh c√¥ng, ch·ªâ c·∫ßn rerender
                st.rerun() 
            # initialize_chat_session s·∫Ω t·ª± hi·ªÉn th·ªã l·ªói n·∫øu c√≥
        else:
            st.error("L·ªói: Kh√¥ng t√¨m th·∫•y Kh√≥a API ho·∫∑c Client ch∆∞a s·∫µn s√†ng. Vui l√≤ng ki·ªÉm tra c·∫•u h√¨nh Kh√≥a API.", icon="üö®")
else:
    st.info("T·∫£i file l√™n tr∆∞·ªõc ƒë·ªÉ k√≠ch ho·∫°t chatbot.")


# --- Khu v·ª±c Chat Interface ---
if st.session_state.chat_session is not None:
    
    # Container ƒë·ªÉ ch·ª©a l·ªãch s·ª≠ chat
    chat_history_container = st.container(height=400, border=True)

    # Hi·ªÉn th·ªã l·ªãch s·ª≠ chat
    for message in st.session_state.chat_history:
        with chat_history_container.chat_message(message["role"]):
            st.markdown(message["content"])

    # Input cho ng∆∞·ªùi d√πng
    user_prompt = st.chat_input("H·ªèi AI v·ªÅ c√°c ch·ªâ s·ªë t√†i ch√≠nh...", key="chat_input_main")
    
    if user_prompt:
        # N·∫øu ng∆∞·ªùi d√πng nh·∫≠p, g·ªçi h√†m x·ª≠ l√Ω chat
        # S·ª¨A L·ªñI: C·∫ßn truy·ªÅn chat_history_container v√†o h√†m x·ª≠ l√Ω
        handle_chatbot_input_popup(user_prompt, chat_history_container)
        st.rerun() # T·∫£i l·∫°i trang ƒë·ªÉ hi·ªÉn th·ªã tin nh·∫Øn m·ªõi ngay l·∫≠p t·ª©c
else:
    st.info("Nh·∫•n n√∫t **'B·∫≠t/Reset Chat'** ƒë·ªÉ kh·ªüi ƒë·ªông phi√™n tr√≤ chuy·ªán d·ª±a tr√™n d·ªØ li·ªáu t√†i ch√≠nh c·ªßa b·∫°n.")
